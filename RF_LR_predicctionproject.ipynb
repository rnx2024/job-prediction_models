{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date_sourced  company_name  \\\n",
      "0   2024-01-01  PRIOjet GmbH   \n",
      "1   2024-01-01    Bettermile   \n",
      "2   2024-01-01     DOSarrest   \n",
      "3   2024-01-02      Europace   \n",
      "4   2024-01-02     ticketbro   \n",
      "\n",
      "                                            position  \\\n",
      "0                       software Developer fullstack   \n",
      "1           fullstack Engineer - kotlin, vue.js, aws   \n",
      "2                            devops Engineer cdn dns   \n",
      "3                             devops Engineer remote   \n",
      "4  fullstack Engineer - react native, react.js, a...   \n",
      "\n",
      "                                     job_description          location  \\\n",
      "0  Hi! Were happy that youre here \\r\\n\\r\\n PRIOje...   Frankfurt am Ma   \n",
      "1  At the moment we only proceed with candidates ...  Berlin-Kreuzberg   \n",
      "2  A multi-billion IT security market and Link11 ...   Frankfurt am Ma   \n",
      "3  At Europace, we have been enabling people to m...            Berlin   \n",
      "4  INTRO\\r\\nHere at ticketbro we bring the smarte...            Berlin   \n",
      "\n",
      "  contract_type language     job_location mode_of_application date_applied  \\\n",
      "0           NaN  English  Company Website                 NaN          NaN   \n",
      "1           NaN  English  Company Website                 NaN          NaN   \n",
      "2           NaN  English  Company Website                 NaN          NaN   \n",
      "3     Permanent  English              NaN                 NaN          NaN   \n",
      "4     Full-time  English  Company Website     Company website   2024-02-09   \n",
      "\n",
      "  applied job_delisted date_rejected  rejected  interview  technical_test  \n",
      "0       0            1           NaN         0          0               0  \n",
      "1       0            1           NaN         0          0               0  \n",
      "2       0            1           NaN         0          0               0  \n",
      "3       0            1           NaN         0          0               0  \n",
      "4       1            0           NaN         1          0               0  \n",
      "Index(['date_sourced', 'company_name', 'position', 'job_description',\n",
      "       'location', 'contract_type', 'language', 'job_location',\n",
      "       'mode_of_application', 'date_applied', 'applied', 'job_delisted',\n",
      "       'date_rejected', 'rejected', 'interview', 'technical_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "file_path = \"\\\\cleaned_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        position  count\n",
      "0           \" software Developer ecm dms w m d \"      1\n",
      "1          \"backend Developer*in ruby on rails \"      1\n",
      "2                       \"java software Developer      1\n",
      "3                  #1 founding frontend Engineer      3\n",
      "4  #englishspeaking! fullstack Developer gen. ai      1\n"
     ]
    }
   ],
   "source": [
    "aggregated_data = data.groupby('position').size().reset_index(name='count')\n",
    "\n",
    "print(aggregated_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target encode position column for easier handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original positions to convert them back later\n",
    "original_positions = aggregated_data['position']\n",
    "\n",
    "# Target encode the positions\n",
    "categorical_columns = ['position']\n",
    "encoder = TargetEncoder(cols=categorical_columns)\n",
    "encoded_data = encoder.fit_transform(aggregated_data, aggregated_data['count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify all columns and values are numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position    float64\n",
      "count         int64\n",
      "dtype: object\n",
      "All columns are numeric.\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data.dtypes)\n",
    "\n",
    "non_numeric_columns = encoded_data.select_dtypes(include=['object']).columns\n",
    "if len(non_numeric_columns) > 0:\n",
    "    for col in non_numeric_columns:\n",
    "        print(f\"Non-numeric column '{col}' unique values: {encoded_data[col].unique()}\")\n",
    "else:\n",
    "    print(\"All columns are numeric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Squared Error: 0.03036734417344173\n",
      "                                      position  predicted\n",
      "740                         software Developer     285.72\n",
      "282                    senior backend Engineer     219.40\n",
      "830                            devops Engineer     210.88\n",
      "654                          android Developer     131.58\n",
      "2613                  senior frontend Engineer     121.34\n",
      "1600                          backend Engineer     116.58\n",
      "1643                             web Developer     103.96\n",
      "653      senior team lead of quality assurance      99.17\n",
      "2578                           project Manager      73.26\n",
      "2847                             app Developer      65.98\n",
      "1412                                hr Manager      61.43\n",
      "2854                            java Developer      60.45\n",
      "2746                          mobile Developer      60.15\n",
      "2278  salesforce crm software Engineering lead      48.11\n",
      "2724                    frontend web Developer      43.54\n",
      "512                   senior android Developer      42.16\n",
      "1881                             data Engineer      40.59\n",
      "201                       salesforce Developer      38.07\n",
      "123               software Developer fullstack      32.87\n",
      "1977  lead software quality assurance Engineer      32.14\n"
     ]
    }
   ],
   "source": [
    "X = encoded_data.drop('count', axis=1)\n",
    "y = encoded_data['count']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RF Model and Create Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Random Forest Mean Squared Error: {mse}\")\n",
    "\n",
    "# Create a dataframe to store predicted values\n",
    "results = pd.DataFrame({'position': X_test.index, 'predicted': predictions})\n",
    "\n",
    "# Map back to original positions\n",
    "results['position'] = results['position'].map(original_positions)\n",
    "\n",
    "results_sorted = results.sort_values(by='predicted', ascending=False)\n",
    "\n",
    "top_20_results = results_sorted.head(20)\n",
    "\n",
    "print(top_20_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore how it goes with linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date_sourced  company_name  \\\n",
      "0   2024-01-01  PRIOjet GmbH   \n",
      "1   2024-01-01    Bettermile   \n",
      "2   2024-01-01     DOSarrest   \n",
      "3   2024-01-02      Europace   \n",
      "4   2024-01-02     ticketbro   \n",
      "\n",
      "                                            position  \\\n",
      "0                       software Developer fullstack   \n",
      "1           fullstack Engineer - kotlin, vue.js, aws   \n",
      "2                            devops Engineer cdn dns   \n",
      "3                             devops Engineer remote   \n",
      "4  fullstack Engineer - react native, react.js, a...   \n",
      "\n",
      "                                     job_description          location  \\\n",
      "0  Hi! Were happy that youre here \\r\\n\\r\\n PRIOje...   Frankfurt am Ma   \n",
      "1  At the moment we only proceed with candidates ...  Berlin-Kreuzberg   \n",
      "2  A multi-billion IT security market and Link11 ...   Frankfurt am Ma   \n",
      "3  At Europace, we have been enabling people to m...            Berlin   \n",
      "4  INTRO\\r\\nHere at ticketbro we bring the smarte...            Berlin   \n",
      "\n",
      "  contract_type language     job_location mode_of_application date_applied  \\\n",
      "0           NaN  English  Company Website                 NaN          NaN   \n",
      "1           NaN  English  Company Website                 NaN          NaN   \n",
      "2           NaN  English  Company Website                 NaN          NaN   \n",
      "3     Permanent  English              NaN                 NaN          NaN   \n",
      "4     Full-time  English  Company Website     Company website   2024-02-09   \n",
      "\n",
      "  applied job_delisted date_rejected  rejected  interview  technical_test  \n",
      "0       0            1           NaN         0          0               0  \n",
      "1       0            1           NaN         0          0               0  \n",
      "2       0            1           NaN         0          0               0  \n",
      "3       0            1           NaN         0          0               0  \n",
      "4       1            0           NaN         1          0               0  \n",
      "Index(['date_sourced', 'company_name', 'position', 'job_description',\n",
      "       'location', 'contract_type', 'language', 'job_location',\n",
      "       'mode_of_application', 'date_applied', 'applied', 'job_delisted',\n",
      "       'date_rejected', 'rejected', 'interview', 'technical_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your dataset\n",
    "file_path = \"C:\\\\Users\\\\acer\\\\Documents\\\\data_analysis_project\\\\cleaned_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Print the column names to verify the presence of 'count'\n",
    "print(data.columns)\n",
    "\n",
    "# Ensure 'count' column is present\n",
    "if 'count' not in data.columns:\n",
    "    data['count'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    position  count\n",
      "0        fullstack Developer    581\n",
      "1         frontend Developer    502\n",
      "2          software Engineer    338\n",
      "3         software Developer    286\n",
      "4  senior frontend Developer    225\n"
     ]
    }
   ],
   "source": [
    "unique_positions_counts = data['position'].value_counts().reset_index()\n",
    "unique_positions_counts.columns = ['position', 'count']\n",
    "\n",
    "print(unique_positions_counts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store original positions for later conversion back\n",
    "original_positions = unique_positions_counts['position']\n",
    "\n",
    "# Encode all categorical variables using Target Encoding\n",
    "categorical_columns = ['position']\n",
    "encoder = TargetEncoder(cols=categorical_columns)\n",
    "encoded_data = encoder.fit_transform(unique_positions_counts, unique_positions_counts['count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X = encoded_data.drop('count', axis=1)\n",
    "y = encoded_data['count']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X = encoded_data.drop('count', axis=1)\n",
    "y = encoded_data['count']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error: 5.4643048068967646e-30\n",
      "                          position  predicted\n",
      "481            fullstack Developer      581.0\n",
      "341             software Developer      286.0\n",
      "1991                 php Developer      195.0\n",
      "924             senior qa Engineer      148.0\n",
      "1574            fullstack Engineer      143.0\n",
      "475                    qa Engineer      130.0\n",
      "1785      senior frontend Engineer      119.0\n",
      "1070                 web Developer      111.0\n",
      "660           senior php Developer       98.0\n",
      "64               frontend Engineer       75.0\n",
      "1896               project Manager       72.0\n",
      "2003                data scientist       67.0\n",
      "12      quality assurance Engineer       62.0\n",
      "583                 java Developer       60.0\n",
      "1586              mobile Developer       59.0\n",
      "45       backend software Engineer       52.0\n",
      "2565  fullstack software Developer       50.0\n",
      "2113        frontend web Developer       44.0\n",
      "1895                cloud Engineer       43.0\n",
      "608            mechanical Engineer       42.0\n"
     ]
    }
   ],
   "source": [
    "# Train Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "linear_predictions = linear_model.predict(X_test)\n",
    "linear_mse = mean_squared_error(y_test, linear_predictions)\n",
    "print(f\"Linear Regression Mean Squared Error: {linear_mse}\")\n",
    "\n",
    "# Create a dataframe to store predicted values\n",
    "linear_results = pd.DataFrame({'position': X_test.index, 'predicted': linear_predictions})\n",
    "\n",
    "# Map back to original positions\n",
    "linear_results['position'] = linear_results['position'].map(original_positions)\n",
    "\n",
    "# Sort the results by predicted counts in descending order\n",
    "linear_results_sorted = linear_results.sort_values(by='predicted', ascending=False)\n",
    "\n",
    "# Select the top 20 job positions with the highest predicted counts\n",
    "linear_top_20_results = linear_results_sorted.head(20)\n",
    "\n",
    "# Print the top 20 results\n",
    "print(linear_top_20_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
